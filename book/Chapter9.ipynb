{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Your First Graph and Running It in a Session\n",
    "\n",
    "First graph and four different ways of execution. Also learning how to set a default session (last execution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/caiolmartinelli/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "time: 35.8 ms\n"
     ]
    }
   ],
   "source": [
    "# Creating the graph\n",
    "x = tf.Variable(3, name='x')\n",
    "y = tf.Variable(4, name='y')\n",
    "f = x*x*y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "time: 71.3 ms\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "time: 39 ms\n"
     ]
    }
   ],
   "source": [
    "result = 0\n",
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "time: 155 ms\n"
     ]
    }
   ],
   "source": [
    "result = 0\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "time: 79.8 ms\n"
     ]
    }
   ],
   "source": [
    "result = 0\n",
    "init = tf.global_variables_initializer()\n",
    "# This will set 'sess' as my default session\n",
    "sess = tf.InteractiveSession()\n",
    "init.run()\n",
    "result = f.eval()\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 104 ms\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 127 ms\n"
     ]
    }
   ],
   "source": [
    "x2 = tf.Variable(2)\n",
    "x2.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "time: 101 ms\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "# Setting 'graph' as the default graph\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "    print(x2.graph is graph)\n",
    "    print(x2.graph is tf.get_default_graph())\n",
    "print(x2.graph is graph)\n",
    "print(x2.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lifecycle of a Node Value\n",
    "\n",
    "Running a graph causes TensorFlow to run all the dependencies associated with the graph (w and x on the example). After the run, the dependencies will be dropped. If you have two graphs that have the same dependencies there is the option to run them both in one only graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n",
      "CPU times: user 11.3 ms, sys: 4.54 ms, total: 15.8 ms\n",
      "Wall time: 14.2 ms\n",
      "time: 53.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n",
      "CPU times: user 14.6 ms, sys: 0 ns, total: 14.6 ms\n",
      "Wall time: 13.1 ms\n",
      "time: 87.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicating for $10 ^ 4$ runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.63 s, sys: 134 ms, total: 2.76 s\n",
      "Wall time: 1.82 s\n",
      "time: 1.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10**4):\n",
    "        y_val = y.eval()\n",
    "        z_val = z.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.58 s, sys: 91.8 ms, total: 1.67 s\n",
      "Wall time: 1.22 s\n",
      "time: 1.23 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(10**4):\n",
    "        y_val, z_val = sess.run([y, z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with TensorFlow\n",
    "## Adjusting linear regression by Normal Equation: \n",
    "$ \\theta = (X^T X)^{-1} X^T y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.52434915\n",
      "time: 46.9 ms\n"
     ]
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    \n",
    "    print(\"MSE =\", mse.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Gradient Descent\n",
    "\n",
    "Adjusting linear regression by gradient descent: $ \\theta^{i+1} = \\theta - \\eta \\nabla_{\\theta}MSE(\\theta) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manualy computing the gradients\n",
    "$ MSE = \\frac{1}{M}\\sum_{n=1}^{M} (\\hat{y_{n}} - y_{n})^2$\n",
    "\n",
    "$ \\hat{y} = X \\theta$\n",
    "\n",
    "$\\nabla_{\\theta}MSE(\\theta) = \\frac{2}{M} X^T (\\hat{y} - y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.6 ms\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 14.243605\n",
      "Epoch 100 MSE = 0.73185533\n",
      "Epoch 200 MSE = 0.5386133\n",
      "Epoch 300 MSE = 0.5333081\n",
      "Epoch 400 MSE = 0.53155\n",
      "Epoch 500 MSE = 0.53018916\n",
      "Epoch 600 MSE = 0.5290989\n",
      "Epoch 700 MSE = 0.52822185\n",
      "Epoch 800 MSE = 0.5275132\n",
      "Epoch 900 MSE = 0.52693903\n",
      "Epoch 1000 MSE = 0.52647233\n",
      "CPU times: user 463 ms, sys: 6.99 ms, total: 470 ms\n",
      "Wall time: 377 ms\n",
      "time: 445 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_epochs = 1001\n",
    "learning_rate = 0.01\n",
    "\n",
    "scaled_housing_data_plus_bias = housing_data_plus_bias\n",
    "scaled_housing_data_plus_bias[:, 1:] = scaler.fit_transform(housing_data_plus_bias[:, 1:])\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using autodiff to compute the grandients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 12.731786\n",
      "Epoch 100 MSE = 0.8906498\n",
      "Epoch 200 MSE = 0.64897776\n",
      "Epoch 300 MSE = 0.6135527\n",
      "Epoch 400 MSE = 0.5918469\n",
      "Epoch 500 MSE = 0.5758504\n",
      "Epoch 600 MSE = 0.5638534\n",
      "Epoch 700 MSE = 0.55480635\n",
      "Epoch 800 MSE = 0.5479522\n",
      "Epoch 900 MSE = 0.54273427\n",
      "Epoch 1000 MSE = 0.5387426\n",
      "CPU times: user 530 ms, sys: 26.5 ms, total: 556 ms\n",
      "Wall time: 491 ms\n",
      "time: 493 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_epochs = 1001\n",
    "learning_rate = 0.01\n",
    "\n",
    "scaled_housing_data_plus_bias = housing_data_plus_bias\n",
    "scaled_housing_data_plus_bias[:, 1:] = scaler.fit_transform(housing_data_plus_bias[:, 1:])\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using an optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Descent Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 6.71938\n",
      "Epoch 100 MSE = 1.0184149\n",
      "Epoch 200 MSE = 0.81773955\n",
      "Epoch 300 MSE = 0.73550314\n",
      "Epoch 400 MSE = 0.6771615\n",
      "Epoch 500 MSE = 0.6350104\n",
      "Epoch 600 MSE = 0.6045326\n",
      "Epoch 700 MSE = 0.5824868\n",
      "Epoch 800 MSE = 0.5665334\n",
      "Epoch 900 MSE = 0.5549832\n",
      "Epoch 1000 MSE = 0.54661614\n",
      "CPU times: user 384 ms, sys: 20.8 ms, total: 405 ms\n",
      "Wall time: 310 ms\n",
      "time: 312 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_epochs = 1001\n",
    "learning_rate = 0.01\n",
    "\n",
    "scaled_housing_data_plus_bias = housing_data_plus_bias\n",
    "scaled_housing_data_plus_bias[:, 1:] = scaler.fit_transform(housing_data_plus_bias[:, 1:])\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 15.942357\n",
      "Epoch 100 MSE = 0.5315806\n",
      "Epoch 200 MSE = 0.52497107\n",
      "Epoch 300 MSE = 0.5244025\n",
      "Epoch 400 MSE = 0.52433175\n",
      "Epoch 500 MSE = 0.5243224\n",
      "Epoch 600 MSE = 0.52432114\n",
      "Epoch 700 MSE = 0.524321\n",
      "Epoch 800 MSE = 0.524321\n",
      "Epoch 900 MSE = 0.52432096\n",
      "Epoch 1000 MSE = 0.52432096\n",
      "CPU times: user 544 ms, sys: 35.6 ms, total: 580 ms\n",
      "Wall time: 470 ms\n",
      "time: 474 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_epochs = 1001\n",
    "learning_rate = 0.01\n",
    "\n",
    "scaled_housing_data_plus_bias = housing_data_plus_bias\n",
    "scaled_housing_data_plus_bias[:, 1:] = scaler.fit_transform(housing_data_plus_bias[:, 1:])\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate, momentum=0.9)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding Data to the Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 848 µs\n"
     ]
    }
   ],
   "source": [
    "housing_target = housing.target.reshape((-1, 1))\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)\n",
    "    idx = np.random.randint(m, size=batch_size)\n",
    "    X_batch = scaled_housing_data_plus_bias[idx]\n",
    "    y_batch = housing_target[idx]\n",
    "    \n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 3.9309347\n",
      "Epoch 100 MSE = 1.0551947\n",
      "Epoch 200 MSE = 0.6202288\n",
      "Epoch 300 MSE = 0.6609783\n",
      "Epoch 400 MSE = 0.48806977\n",
      "Epoch 500 MSE = 0.515194\n",
      "Epoch 600 MSE = 0.41066602\n",
      "Epoch 700 MSE = 0.49822804\n",
      "Epoch 800 MSE = 0.73221624\n",
      "Epoch 900 MSE = 0.6849343\n",
      "Epoch 1000 MSE = 0.44657856\n",
      "time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer() \n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            _, mse_val = sess.run([training_op, mse], feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse_val)\n",
    "\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: investigate why the batch algorithm is so much slower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Restoring Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Gradient Descent Optimizer version and saving sessions per 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 703 µs\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('chp9/models/'):\n",
    "    if not os.path.exists('chp9/'):\n",
    "        os.mkdir('chp9')\n",
    "    os.mkdir('chp9/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 68.9 ms\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('chp9/models/lr_gdo'):\n",
    "    os.mkdir('chp9/models/lr_gdo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 3.2112293\n",
      "Epoch 200 MSE = 0.5408854\n",
      "Epoch 400 MSE = 0.53283066\n",
      "Epoch 600 MSE = 0.5292797\n",
      "Epoch 800 MSE = 0.5272719\n",
      "Epoch 1000 MSE = 0.52611387\n",
      "WARNING:tensorflow:From /home/caiolmartinelli/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "CPU times: user 606 ms, sys: 106 ms, total: 712 ms\n",
      "Wall time: 618 ms\n",
      "time: 703 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_epochs = 1001\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "        if epoch % 200 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "            saver.save(sess, f'chp9/models/lr_gdo/lr_gdo_epoch{epoch}.ckpt')\n",
    "\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/caiolmartinelli/.local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from chp9/models/lr_gdo/lr_gdo_epoch200.ckpt\n",
      "[[ 2.0460427 ]\n",
      " [ 0.85075015]\n",
      " [ 0.18975708]\n",
      " [-0.21466142]\n",
      " [ 0.23740135]\n",
      " [ 0.03893556]\n",
      " [-0.05524277]\n",
      " [-0.57464874]\n",
      " [-0.5447832 ]]\n",
      "MSE = 0.5408854\n",
      "INFO:tensorflow:Restoring parameters from chp9/models/lr_gdo/lr_gdo_epoch1000.ckpt\n",
      "[[ 2.0685523e+00]\n",
      " [ 8.4960401e-01]\n",
      " [ 1.3333330e-01]\n",
      " [-2.8302097e-01]\n",
      " [ 3.1125107e-01]\n",
      " [ 5.4262805e-04]\n",
      " [-4.0985990e-02]\n",
      " [-7.7482873e-01]\n",
      " [-7.4682987e-01]]\n",
      "MSE = 0.52611387\n",
      "time: 56.6 ms\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'chp9/models/lr_gdo/lr_gdo_epoch200.ckpt')\n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)\n",
    "    print(\"MSE =\", mse.eval())\n",
    "    \n",
    "    saver.restore(sess, 'chp9/models/lr_gdo/lr_gdo_epoch1000.ckpt')\n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)\n",
    "    print(\"MSE =\", mse.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Graph and Training curves Using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 258 ms\n"
     ]
    }
   ],
   "source": [
    "now = datetime.utcnow().strftime(\"%Y%m%d%%M%S\")\n",
    "root_logdir = 'chp9/models/lr_gdo/tf_logs'\n",
    "log_dir = f'{root_logdir}/run-{now}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 754 ms, sys: 159 ms, total: 914 ms\n",
      "Wall time: 840 ms\n",
      "time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_epochs = 1001\n",
    "learning_rate = 0.01\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%%M%S\")\n",
    "root_logdir = 'chp9/models/lr_gdo/tf_logs'\n",
    "logdir = f'{root_logdir}/run-{now}'\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "# TensorBoard part\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "        if epoch % 200 == 0:\n",
    "            #print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "            saver.save(sess, f'chp9/models/lr_gdo/lr_gdo_epoch{epoch}.ckpt')\n",
    "        if epoch % 20 == 0:\n",
    "            summary_str = mse_summary.eval()\n",
    "            file_writer.add_summary(summary_str, epoch)\n",
    "    best_theta = theta.eval()\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run on terminal, in the directory of this notebook:\n",
    "```shell\n",
    "$ tensorboard --logdir chp9/models/lr_gdo/tf_logs/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
